#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Coqui TTS –Ω–∞ –∞—É–¥–∏–æ—Å—ç–º–ø–ª–∞—Ö –¥–µ–≤–æ—á–∫–∏
–°–æ–∑–¥–∞–µ—Ç –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –¥–ª—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞
"""

import os
import sys
import json
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional
import subprocess
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('voice_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VoiceCloner:
    """–ö–ª–∞—Å—Å –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é Coqui TTS"""
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.audio_dir = self.project_root / "uploads" / "audio"
        self.models_dir = self.project_root / "models"
        self.coqui_dir = self.models_dir / "coqui_tts"
        self.training_dir = self.project_root / "training"
        self.output_dir = self.project_root / "models" / "voice_clone"
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.training_dir.mkdir(exist_ok=True)
        self.output_dir.mkdir(exist_ok=True)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.training_config = {
            "model_name": "voice_clone",
            "language": "ru",
            "speaker_name": "girl_avatar",
            "sample_rate": 22050,
            "max_audio_length": 10.0,  # —Å–µ–∫—É–Ω–¥—ã
            "min_audio_length": 1.0,   # —Å–µ–∫—É–Ω–¥—ã
            "epochs": 1000,
            "batch_size": 8,
            "learning_rate": 0.001,
            "validation_split": 0.1
        }
    
    def print_header(self, title: str):
        """–í—ã–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        print(f"\n{'='*60}")
        print(f"üé§ {title}")
        print(f"{'='*60}")
    
    def print_step(self, step: str):
        """–í—ã–≤–æ–¥ —à–∞–≥–∞"""
        print(f"\nüìã {step}")
        print("-" * 40)
    
    def run_command(self, command: List[str], cwd: Optional[Path] = None) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã"""
        try:
            result = subprocess.run(
                command, 
                capture_output=True, 
                text=True, 
                cwd=cwd,
                check=True
            )
            logger.info(f"–ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: {' '.join(command)}")
            return True
        except subprocess.CalledProcessError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e.stderr}")
            return False
    
    def prepare_audio_data(self) -> bool:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        self.print_step("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö")
        
        if not self.audio_dir.exists():
            logger.error(f"–ü–∞–ø–∫–∞ —Å –∞—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.audio_dir}")
            return False
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        prepared_dir = self.training_dir / "prepared_audio"
        prepared_dir.mkdir(exist_ok=True)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ WAV –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        audio_files = list(self.audio_dir.glob("*.ogg"))
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(audio_files)} –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤")
        
        converted_count = 0
        for audio_file in audio_files:
            output_file = prepared_dir / f"{audio_file.stem}.wav"
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV —Å –Ω—É–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            success = self.run_command([
                "ffmpeg", "-i", str(audio_file),
                "-ar", str(self.training_config["sample_rate"]),
                "-ac", "1",  # –º–æ–Ω–æ
                "-f", "wav",
                str(output_file)
            ])
            
            if success:
                converted_count += 1
                logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {audio_file.name}")
            else:
                logger.warning(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {audio_file.name}")
        
        logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {converted_count}/{len(audio_files)} —Ñ–∞–π–ª–æ–≤")
        return converted_count > 0
    
    def create_metadata(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        self.print_step("–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
        
        prepared_dir = self.training_dir / "prepared_audio"
        metadata_file = self.training_dir / "metadata.csv"
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ WAV —Ñ–∞–π–ª–æ–≤
        wav_files = list(prepared_dir.glob("*.wav"))
        
        if not wav_files:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω—ã WAV —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        with open(metadata_file, 'w', encoding='utf-8') as f:
            f.write("filename|text|speaker_name\n")
            
            for wav_file in wav_files:
                # –î–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
                # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                text = "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"
                speaker = self.training_config["speaker_name"]
                
                f.write(f"{wav_file.name}|{text}|{speaker}\n")
        
        logger.info(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {metadata_file}")
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(wav_files)} –∑–∞–ø–∏—Å–µ–π")
        return True
    
    def create_training_config(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        self.print_step("–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è")
        
        config = {
            "model": "tts_models/multilingual/multi-dataset/your_tts",
            "run_name": self.training_config["model_name"],
            "run_description": "Voice cloning for digital avatar",
            
            "audio": {
                "sample_rate": self.training_config["sample_rate"],
                "max_audio_length": self.training_config["max_audio_length"],
                "min_audio_length": self.training_config["min_audio_length"]
            },
            
            "training": {
                "epochs": self.training_config["epochs"],
                "batch_size": self.training_config["batch_size"],
                "learning_rate": self.training_config["learning_rate"],
                "validation_split": self.training_config["validation_split"],
                "save_step": 100,
                "print_step": 10,
                "save_n_checkpoints": 5,
                "save_best_after": 1000,
                "target_loss": 0.5,
                "print_eval": True,
                "mixed_precision": True,
                "distributed_backend": "nccl",
                "distributed_url": "tcp://localhost:54321"
            },
            
            "paths": {
                "output_path": str(self.output_dir),
                "data_path": str(self.training_dir / "prepared_audio"),
                "meta_file_train": str(self.training_dir / "metadata.csv")
            }
        }
        
        config_file = self.training_dir / "config.json"
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_file}")
        return True
    
    def start_training(self) -> bool:
        """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è"""
        self.print_step("–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
        
        if not self.coqui_dir.exists():
            logger.error("Coqui TTS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –ø–∞–ø–∫—É Coqui TTS
        os.chdir(self.coqui_dir)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        training_command = [
            sys.executable, "TTS/bin/train_tts.py",
            "--config_path", str(self.training_dir / "config.json")
        ]
        
        logger.info("–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
        logger.info(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(training_command)}")
        
        success = self.run_command(training_command, cwd=self.coqui_dir)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É
        os.chdir(self.project_root)
        
        if success:
            logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            return True
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è")
            return False
    
    def test_voice_clone(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞"""
        self.print_step("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞")
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        model_files = list(self.output_dir.glob("*.pth"))
        if not model_files:
            logger.error("–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
        best_model = max(model_files, key=lambda x: x.stat().st_mtime)
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {best_model}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç
        test_script = self.training_dir / "test_voice.py"
        
        test_code = f'''
import sys
import os
sys.path.append("{self.coqui_dir}")

from TTS.api import TTS

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
tts = TTS(model_path="{best_model}")

# –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
text = "–ü—Ä–∏–≤–µ—Ç! –Ø —Ü–∏—Ñ—Ä–æ–≤–æ–π –∞–≤–∞—Ç–∞—Ä. –ö–∞–∫ –¥–µ–ª–∞?"

# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å
output_path = "{self.output_dir}/test_output.wav"
tts.tts_to_file(text=text, file_path=output_path, speaker="{self.training_config['speaker_name']}")

print(f"–¢–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {{output_path}}")
'''
        
        with open(test_script, 'w') as f:
            f.write(test_code)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
        success = self.run_command([
            sys.executable, str(test_script)
        ])
        
        if success:
            logger.info("‚úÖ –¢–µ—Å—Ç –≥–æ–ª–æ—Å–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return False
    
    def create_voice_config(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞"""
        self.print_step("–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞")
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        model_files = list(self.output_dir.glob("*.pth"))
        if model_files:
            best_model = max(model_files, key=lambda x: x.stat().st_mtime)
        else:
            best_model = None
        
        voice_config = {
            "voice_clone": {
                "enabled": True,
                "model_path": str(best_model) if best_model else None,
                "speaker_name": self.training_config["speaker_name"],
                "language": self.training_config["language"],
                "sample_rate": self.training_config["sample_rate"],
                "training_info": {
                    "epochs": self.training_config["epochs"],
                    "batch_size": self.training_config["batch_size"],
                    "learning_rate": self.training_config["learning_rate"],
                    "audio_files_used": len(list((self.training_dir / "prepared_audio").glob("*.wav")))
                }
            }
        }
        
        config_file = self.output_dir / "voice_config.json"
        with open(config_file, 'w') as f:
            json.dump(voice_config, f, indent=2)
        
        logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_file}")
        return True
    
    def run_voice_cloning(self) -> None:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞"""
        self.print_header("–ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï –ì–û–õ–û–°–ê –î–õ–Ø –¶–ò–§–†–û–í–û–ì–û –ê–í–ê–¢–ê–†–ê")
        
        results = {}
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        results["–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ"] = self.prepare_audio_data()
        results["–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"] = self.create_metadata()
        results["–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"] = self.create_training_config()
        
        # –û–±—É—á–µ–Ω–∏–µ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –û–±—É—á–µ–Ω–∏–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤!")
        print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
        
        user_input = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ? (y/n): ")
        if user_input.lower() == 'y':
            results["–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"] = self.start_training()
            results["–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞"] = self.test_voice_clone()
        else:
            results["–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"] = False
            results["–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞"] = False
            print("–û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
        
        results["–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–∞"] = self.create_voice_config()
        
        # –û—Ç—á–µ—Ç
        self.print_step("–û—Ç—á–µ—Ç –æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –≥–æ–ª–æ—Å–∞")
        
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        for step, status in results.items():
            icon = "‚úÖ" if status else "‚ùå"
            print(f"   {icon} {step}")
        
        success_count = sum(results.values())
        total_count = len(results)
        
        print(f"\nüéØ –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {success_count}/{total_count} —ç—Ç–∞–ø–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
        
        if success_count == total_count:
            print("üéâ –ì–æ–ª–æ—Å —É—Å–ø–µ—à–Ω–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω!")
        else:
            print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —ç—Ç–∞–ø—ã –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        with open("voice_cloning_report.json", "w") as f:
            json.dump({
                "results": results,
                "training_config": self.training_config,
                "output_dir": str(self.output_dir),
                "total_steps": total_count,
                "successful_steps": success_count
            }, f, indent=2)
        
        print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ voice_cloning_report.json")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    cloner = VoiceCloner()
    cloner.run_voice_cloning()

if __name__ == "__main__":
    main() 